{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:16.391089Z",
     "start_time": "2022-10-05T11:12:16.388589Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:16.394182Z",
     "start_time": "2022-10-05T11:12:16.391780Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:17.182499Z",
     "start_time": "2022-10-05T11:12:16.395222Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:17.185856Z",
     "start_time": "2022-10-05T11:12:17.183746Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set a seed value\n",
    "# seed = 42 \n",
    "# os.environ['PYTHONHASHSEED']=str(seed)\n",
    "# torch.manual_seed(0)\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:17.425084Z",
     "start_time": "2022-10-05T11:12:17.186748Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import model\n",
    "\n",
    "import utils\n",
    "from training import get_config, get_config_fedir, ImgDataset, evaluate_model\n",
    "import federated_learning as fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:17.429729Z",
     "start_time": "2022-10-05T11:12:17.426264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define dataset and settings.\n",
    "\n",
    "dataset_name = 'cifar_10'\n",
    "# dataset_name = 'cifar_100'\n",
    "# dataset_name = 'tiny_imagenet_200'\n",
    "# dataset_name = 'svhn'\n",
    "# dataset_name = 'fashion_mnist'\n",
    "\n",
    "# Define distribution settings.\n",
    "num_clients = 100  # [10, 50, 100]\n",
    "if num_clients == 10:\n",
    "    num_participation = 10\n",
    "elif num_clients == 50:\n",
    "    num_participation = 10\n",
    "elif num_clients == 100:\n",
    "    num_participation = 20\n",
    "client_idxes = list(range(num_clients))\n",
    "\n",
    "beta = 0.5 # [0.1, 0.5, 5]\n",
    "\n",
    "client_data_dir = os.path.join('./client_data/', dataset_name + '_c_{}_beta_{}'.format(num_clients, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:17.441122Z",
     "start_time": "2022-10-05T11:12:17.430937Z"
    }
   },
   "outputs": [],
   "source": [
    "data_config, train_config = get_config(dataset_name)\n",
    "\n",
    "# Data config.\n",
    "img_size = data_config['img_size']\n",
    "channels = data_config['channels']\n",
    "batch_size = data_config['batch_size']\n",
    "train_transform = data_config['train_transform']\n",
    "test_transform = data_config['test_transform']\n",
    "\n",
    "# Training config.\n",
    "fedir_args = get_config_fedir()\n",
    "num_rounds = train_config['rounds']\n",
    "num_local_epochs = train_config['local_epochs']\n",
    "save_interval = train_config['save_interval']\n",
    "\n",
    "fedir_args['mu'] = 10   # [0.001, 0.01, 0.1, 0.5, 1, 3, 5, 10] \n",
    "\n",
    "fedir_args['loss'] = 'contrastive'      # ['contrastive', 'mse', 'neg_cosine']\n",
    "fedir_args['scaling'] = 'cosine'        # ['avg', 'cosine', 'cka']\n",
    "\n",
    "optim = train_config['optim']      # ['sgd', 'adam']\n",
    "optim_args = None\n",
    "if optim == 'sgd':\n",
    "    optim_args = {\n",
    "        'lr': train_config['lr'], \n",
    "        'weight_decay': train_config['weight_decay'], \n",
    "        'momentum' : train_config['momentum'],\n",
    "    }\n",
    "elif optim == 'adam':\n",
    "    optim_args = {'lr': train_config['lr']} \n",
    "\n",
    "# b: beta, le: num_local_epochs, mu: balancing parameter\n",
    "save_dir = os.path.join('./output/fedir', dataset_name + '_c_{}_b_{}_le_{}_mu_{}_l_{}_sim_{}_opt_{}_lr_{}'.format(\n",
    "    num_clients,\n",
    "    beta, \n",
    "    num_local_epochs, \n",
    "    fedir_args['mu'],\n",
    "    fedir_args['loss'], \n",
    "    fedir_args['scaling'],\n",
    "    optim,\n",
    "    optim_args['lr']\n",
    "))\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print(data_config)\n",
    "print(train_config)\n",
    "print(fedir_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:17.445058Z",
     "start_time": "2022-10-05T11:12:17.442544Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_linear_mu():\n",
    "#     num_schedule_rounds = num_rounds - flat_rounds * 2\n",
    "#     mu_schedule = [ini_mu] * flat_rounds\n",
    "#     mu_schedule.extend(np.linspace(ini_mu, max_mu, num_schedule_rounds))\n",
    "#     mu_schedule.extend([max_mu] * flat_rounds)\n",
    "#     return mu_schedule\n",
    "\n",
    "# def get_linear_mu():\n",
    "#     num_schedule_rounds = num_rounds - (start_linear + end_linear)\n",
    "#     mu_schedule = [ini_mu] * start_linear\n",
    "#     mu_schedule.extend(np.linspace(ini_mu, max_mu, num_schedule_rounds))\n",
    "#     mu_schedule.extend([max_mu] * end_linear)\n",
    "#     return mu_schedule\n",
    "\n",
    "# mu_schedule = get_linear_mu()\n",
    "# plot_config = utils.ACC_PLOT_CONFIG.copy()\n",
    "# plot_config['figsize'] = (12, 6)\n",
    "# plot_config['save_dir'] = os.path.join(save_dir, 'mu.png')\n",
    "# plot_config['show_img'] = True\n",
    "# plot_config['xlabel'] = 'rounds'\n",
    "# plot_config['ylabel'] = 'mu'\n",
    "# plot_config['labels'] = ['mu']\n",
    "# data_list = [\n",
    "#     mu_schedule\n",
    "# ]\n",
    "# utils.save_plot(data_list, plot_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:17.520342Z",
     "start_time": "2022-10-05T11:12:17.447366Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data.\n",
    "data_dir = os.path.join('../datasets/', dataset_name)\n",
    "\n",
    "# Centralized testset for global model evaluation.\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "test_data = ImgDataset(test_dir, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "\n",
    "num_classes = len(test_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:17.890864Z",
     "start_time": "2022-10-05T11:12:17.522096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define client data.\n",
    "client_loaders = []\n",
    "for client_idx in range(num_clients):\n",
    "    data_dir = os.path.join(client_data_dir, str(client_idx))\n",
    "    dataset = ImgDataset(data_dir, transform=train_transform)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    # data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "    client_loaders.append(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:18.301813Z",
     "start_time": "2022-10-05T11:12:17.892611Z"
    }
   },
   "outputs": [],
   "source": [
    "client_loader = client_loaders[0]\n",
    "\n",
    "# Print a few images.\n",
    "dataiter = iter(client_loader)\n",
    "images, labels = dataiter.next()\n",
    "utils.show_img_tensor(torchvision.utils.make_grid(images[:32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:21.591004Z",
     "start_time": "2022-10-05T11:12:18.303388Z"
    }
   },
   "outputs": [],
   "source": [
    "# Global model.\n",
    "if dataset_name == 'cifar_10' or dataset_name == 'svhn' or dataset_name == 'fashion_mnist':\n",
    "    glob_model = model.cnn(num_classes=num_classes)\n",
    "    fedir_args['inter_layers'] = ['conv1', 'conv2', 'conv3', 'fc1', 'fc2']                                # Which intermediate representions to use.\n",
    "    # fedir_args['inter_layers'] = ['conv1', 'conv2', 'fc']\n",
    "    # fedir_args['inter_layers'] = ['conv1', 'conv2', 'conv3', 'conv4', 'fc1', 'fc2']\n",
    "elif dataset_name == 'cifar_100' or dataset_name == 'tiny_imagenet_200':\n",
    "    glob_model = model.resnet20(num_classes=num_classes, image_size=img_size)\n",
    "    fedir_args['inter_layers'] = ['conv1', 'block1', 'block2', 'block3']\n",
    "\n",
    "glob_model.to(device)\n",
    "glob_w = glob_model.state_dict()\n",
    "\n",
    "# Initialize prev_w for each client.\n",
    "prev_w_dict = dict()\n",
    "for client_idx in range(num_clients):\n",
    "    prev_w_dict[client_idx] = copy.deepcopy(glob_w)\n",
    "\n",
    "# For logging model performance.\n",
    "performance_dict, performance_log = dict(), dict()\n",
    "metric_keys = ['g_train_loss', 'g_train_acc', 'g_test_loss', 'g_test_acc']\n",
    "_, performance_log = utils.get_performance_loggers(metric_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T11:12:22.685568Z",
     "start_time": "2022-10-05T11:12:21.592122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Automatic resuming from checkpoint.\n",
    "log_path = os.path.join(save_dir, 'performance_log.pickle')\n",
    "if os.path.isfile(log_path):\n",
    "    performance_log = utils.load_pickle(log_path)\n",
    "start_round = len(performance_log[metric_keys[0]])\n",
    "\n",
    "# Reload global and previous local models.\n",
    "if start_round > 0:\n",
    "    glob_model.load_state_dict(torch.load(os.path.join(save_dir, 'g_r_{}.pth'.format(start_round))))\n",
    "    glob_w = glob_model.state_dict()\n",
    "    prev_w_dict = torch.load(os.path.join(save_dir, 'prev_w.pth'))\n",
    "    for client_idx in range(num_clients):\n",
    "        prev_w_dict[client_idx] = copy.deepcopy(glob_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:32:08.488000Z",
     "start_time": "2022-10-05T11:12:22.686723Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mu_schedule = get_linear_mu()\n",
    "\n",
    "# Training.\n",
    "for round_no in range(start_round, num_rounds):\n",
    "    utils.print_separator(text='Round: {} / {}'.format(round_no + 1, num_rounds))\n",
    "    \n",
    "    # Evaluate the global model.\n",
    "    test_loss, test_acc = evaluate_model(glob_model, test_loader)\n",
    "    performance_log['g_test_loss'].append(test_loss)\n",
    "    performance_log['g_test_acc'].append(test_acc)\n",
    "    \n",
    "    # fedir_args['mu'], _ = get_mu(performance_log['g_train_acc'])\n",
    "    # fedir_args['mu'] = mu_schedule[round_no]\n",
    "    \n",
    "    participating_clients = sorted(np.random.choice(client_idxes, size=num_participation, replace=False))\n",
    "    print('participating_clients:', participating_clients)\n",
    "    \n",
    "    # Local training.\n",
    "    client_updates = dict()\n",
    "    for client_idx in participating_clients:\n",
    "        print('client:', client_idx)\n",
    "        client_loader = client_loaders[client_idx]\n",
    "        client_update = fl.local_update_fedir(glob_model, prev_w_dict[client_idx], client_loader, num_local_epochs, optim, optim_args, fedir_args)\n",
    "        for key in ['local_w', 'num_samples', 'train_loss', 'train_acc']:\n",
    "            client_updates.setdefault(key, list()).append(client_update[key])\n",
    "        prev_w_dict[client_idx] = copy.deepcopy(client_update['local_w'])\n",
    "    \n",
    "    # Model aggregation.\n",
    "    glob_w = fl.weighted_averaging(client_updates['local_w'], client_updates['num_samples'])\n",
    "    glob_model.load_state_dict(glob_w)\n",
    "    \n",
    "    # Average local performance.\n",
    "    performance_log['g_train_loss'].append(sum(client_updates['train_loss'])/len(client_updates['train_loss']))\n",
    "    performance_log['g_train_acc'].append(sum(client_updates['train_acc'])/len(client_updates['train_acc']))\n",
    "    \n",
    "    # Save global model.\n",
    "    if (round_no + 1) % save_interval == 0:\n",
    "        torch.save(glob_model.state_dict(), os.path.join(save_dir, 'g_r_{}.pth'.format(round_no + 1)))\n",
    "        torch.save(prev_w_dict, os.path.join(save_dir, 'prev_w.pth'))\n",
    "        utils.save_pickle(log_path, performance_log)\n",
    "    \n",
    "    for key in sorted(metric_keys):\n",
    "        print(key, ': ',  performance_log[key][-1])\n",
    "    print('mu', fedir_args['mu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:33:05.932344Z",
     "start_time": "2022-10-05T18:32:08.489351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the final global model on clients.\n",
    "c_loss_list, c_acc_list = [], []\n",
    "for client_idx in range(num_clients):\n",
    "    client_loader = client_loaders[client_idx]\n",
    "    train_loss, train_acc = fl.evaluate_model(glob_model, client_loader, tqdm_desc='client {}/{}'.format(client_idx, num_clients))\n",
    "    c_loss_list.append(train_loss)\n",
    "    c_acc_list.append(train_acc)\n",
    "\n",
    "performance_log['final_g_train_loss'] = sum(c_loss_list) / len(c_loss_list)\n",
    "performance_log['final_g_train_acc'] = sum(c_acc_list) / len(c_acc_list)\n",
    "    \n",
    "# Evaluate the global model.\n",
    "test_loss, test_acc = evaluate_model(glob_model, test_loader)\n",
    "performance_log['final_g_test_loss'] = test_loss\n",
    "performance_log['final_g_test_acc'] = test_acc\n",
    "\n",
    "utils.save_pickle(log_path, performance_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:33:06.900681Z",
     "start_time": "2022-10-05T18:33:05.933461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot training history.\n",
    "performance_log = utils.load_pickle(log_path)\n",
    "\n",
    "loss_plot_config = utils.LOSS_PLOT_CONFIG.copy()\n",
    "loss_plot_config['figsize'] = (12, 6)\n",
    "loss_plot_config['save_dir'] = os.path.join(save_dir, 'loss.png')\n",
    "loss_plot_config['show_img'] = True\n",
    "loss_plot_config['xlabel'] = 'rounds'\n",
    "loss_plot_config['labels'] = ['g_train_loss', 'g_test_loss']\n",
    "data_list = [\n",
    "    performance_log['g_train_loss'] + [performance_log['final_g_train_loss']],\n",
    "    performance_log['g_test_loss'] + [performance_log['final_g_test_loss']]\n",
    "]\n",
    "utils.save_plot(data_list, loss_plot_config)\n",
    "\n",
    "acc_plot_config = utils.ACC_PLOT_CONFIG.copy()\n",
    "acc_plot_config['figsize'] = (12, 6)\n",
    "acc_plot_config['save_dir'] = os.path.join(save_dir, 'accuracy.png')\n",
    "acc_plot_config['show_img'] = True\n",
    "acc_plot_config['xlabel'] = 'rounds'\n",
    "acc_plot_config['labels'] = ['g_train_acc', 'g_test_acc']\n",
    "data_list = [\n",
    "    performance_log['g_train_acc'] + [performance_log['final_g_train_acc']],\n",
    "    performance_log['g_test_acc'] + [performance_log['final_g_test_acc']]\n",
    "]\n",
    "utils.save_plot(data_list, acc_plot_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T18:33:08.208019Z",
     "start_time": "2022-10-05T18:33:06.901901Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reload saved global model.\n",
    "if dataset_name == 'cifar_10' or dataset_name == 'svhn' or dataset_name == 'fashion_mnist':\n",
    "    glob_model = model.cnn(num_classes=num_classes)\n",
    "elif dataset_name == 'cifar_100' or dataset_name == 'tiny_imagenet_200':\n",
    "    glob_model = model.resnet20(num_classes=num_classes, image_size=img_size)\n",
    "    \n",
    "glob_model.to(device)\n",
    "glob_model.load_state_dict(torch.load(os.path.join(save_dir, 'g_r_{}.pth'.format(num_rounds))))\n",
    "\n",
    "# Evaluate the global model.\n",
    "test_loss, test_acc = evaluate_model(glob_model, test_loader)\n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-05T11:12:17.816Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
