{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:27.190527Z",
     "start_time": "2022-10-06T01:18:27.180915Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:27.193612Z",
     "start_time": "2022-10-06T01:18:27.191654Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:27.960932Z",
     "start_time": "2022-10-06T01:18:27.197156Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:27.964909Z",
     "start_time": "2022-10-06T01:18:27.962296Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set a seed value\n",
    "# seed = 42 \n",
    "# os.environ['PYTHONHASHSEED']=str(seed)\n",
    "# torch.manual_seed(0)\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:28.160968Z",
     "start_time": "2022-10-06T01:18:27.966469Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import model\n",
    "\n",
    "import utils\n",
    "from training import get_config, get_config_moon, ImgDataset, evaluate_model\n",
    "import federated_learning as fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:28.165172Z",
     "start_time": "2022-10-06T01:18:28.162164Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define dataset and settings.\n",
    "\n",
    "dataset_name = 'cifar_10'\n",
    "# dataset_name = 'cifar_100'\n",
    "# dataset_name = 'tiny_imagenet_200'\n",
    "# dataset_name = 'svhn'\n",
    "# dataset_name = 'fashion_mnist'\n",
    "\n",
    "# Define distribution settings.\n",
    "num_clients = 100  # [10, 50, 100]\n",
    "if num_clients == 10:\n",
    "    num_participation = 10\n",
    "elif num_clients == 50:\n",
    "    num_participation = 10\n",
    "elif num_clients == 100:\n",
    "    num_participation = 20\n",
    "client_idxes = list(range(num_clients))\n",
    "\n",
    "beta = 0.5 # [0.1, 0.5, 5]\n",
    "\n",
    "client_data_dir = os.path.join('./client_data/', dataset_name + '_c_{}_beta_{}'.format(num_clients, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:28.171966Z",
     "start_time": "2022-10-06T01:18:28.166181Z"
    }
   },
   "outputs": [],
   "source": [
    "data_config, train_config = get_config(dataset_name)\n",
    "\n",
    "# Data config.\n",
    "img_size = data_config['img_size']\n",
    "channels = data_config['channels']\n",
    "batch_size = data_config['batch_size']\n",
    "train_transform = data_config['train_transform']\n",
    "test_transform = data_config['test_transform']\n",
    "\n",
    "# Training config.\n",
    "optim = train_config['optim']      # ['sgd', 'adam']\n",
    "optim_args = None\n",
    "if optim == 'sgd':\n",
    "    optim_args = {\n",
    "        'lr': train_config['lr'], \n",
    "        'weight_decay': train_config['weight_decay'], \n",
    "        'momentum' : train_config['momentum'],\n",
    "    }\n",
    "elif optim_args == 'adam':\n",
    "    optim_args = {'lr': train_config['lr']}\n",
    "\n",
    "fedcka_args = {\n",
    "    'mu': 1,      # [0.1, 1, 3, 5, 10]\n",
    "}\n",
    "\n",
    "num_rounds = train_config['rounds']\n",
    "num_local_epochs = train_config['local_epochs']\n",
    "save_interval = train_config['save_interval']\n",
    "\n",
    "# b: beta, le: num_local_epochs, mu: balancing parameter\n",
    "save_dir = os.path.join('./output/fedcka', dataset_name + '_c_{}_b_{}_le_{}_mu_{}_opt_{}_lr_{}'.format(num_clients, beta, num_local_epochs, fedcka_args['mu'], optim, optim_args['lr']))\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print(data_config)\n",
    "print(train_config)\n",
    "print(fedcka_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:28.235847Z",
     "start_time": "2022-10-06T01:18:28.172984Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data.\n",
    "data_dir = os.path.join('../datasets/', dataset_name)\n",
    "\n",
    "# Centralized testset for global model evaluation.\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "test_data = ImgDataset(test_dir, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "\n",
    "num_classes = len(test_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:28.596236Z",
     "start_time": "2022-10-06T01:18:28.237906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define client data.\n",
    "client_loaders = []\n",
    "for client_idx in range(num_clients):\n",
    "    data_dir = os.path.join(client_data_dir, str(client_idx))\n",
    "    dataset = ImgDataset(data_dir, transform=train_transform)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    # data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "    client_loaders.append(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:28.988602Z",
     "start_time": "2022-10-06T01:18:28.597705Z"
    }
   },
   "outputs": [],
   "source": [
    "client_loader = client_loaders[0]\n",
    "\n",
    "# Print a few images.\n",
    "dataiter = iter(client_loader)\n",
    "images, labels = dataiter.next()\n",
    "utils.show_img_tensor(torchvision.utils.make_grid(images[:32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:32.090682Z",
     "start_time": "2022-10-06T01:18:28.990112Z"
    }
   },
   "outputs": [],
   "source": [
    "# Global model.\n",
    "if dataset_name == 'cifar_10' or dataset_name == 'svhn' or dataset_name == 'fashion_mnist':\n",
    "    glob_model = model.cnn(num_classes=num_classes)\n",
    "    fedcka_args['inter_layers'] = ['conv1', 'conv2']                                # Which intermediate representions to use.\n",
    "elif dataset_name == 'cifar_100' or dataset_name == 'tiny_imagenet_200':\n",
    "    glob_model = model.resnet20(num_classes=num_classes, image_size=img_size)\n",
    "    fedcka_args['inter_layers'] = ['conv1', 'block1']\n",
    "    \n",
    "glob_model.to(device)\n",
    "glob_w = glob_model.state_dict()\n",
    "\n",
    "# Initialize prev_w for each client.\n",
    "prev_w_dict = dict()\n",
    "for client_idx in range(num_clients):\n",
    "    prev_w_dict[client_idx] = copy.deepcopy(glob_w)\n",
    "\n",
    "# For logging model performance.\n",
    "performance_dict, performance_log = dict(), dict()\n",
    "metric_keys = ['g_train_loss', 'g_train_acc', 'g_test_loss', 'g_test_acc']\n",
    "_, performance_log = utils.get_performance_loggers(metric_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T01:18:33.127131Z",
     "start_time": "2022-10-06T01:18:32.091807Z"
    }
   },
   "outputs": [],
   "source": [
    "# Automatic resuming from checkpoint.\n",
    "log_path = os.path.join(save_dir, 'performance_log.pickle')\n",
    "if os.path.isfile(log_path):\n",
    "    performance_log = utils.load_pickle(log_path)\n",
    "start_round = len(performance_log[metric_keys[0]])\n",
    "\n",
    "# Reload global and previous local models.\n",
    "if start_round > 0:\n",
    "    glob_model.load_state_dict(torch.load(os.path.join(save_dir, 'g_r_{}.pth'.format(start_round))))\n",
    "    glob_w = glob_model.state_dict()\n",
    "    prev_w_dict = torch.load(os.path.join(save_dir, 'prev_w.pth'))\n",
    "    for client_idx in range(num_clients):\n",
    "        prev_w_dict[client_idx] = copy.deepcopy(glob_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T07:16:00.423480Z",
     "start_time": "2022-10-06T01:18:33.128393Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training.\n",
    "for round_no in range(start_round, num_rounds):\n",
    "    utils.print_separator(text='Round: {} / {}'.format(round_no + 1, num_rounds))\n",
    "    \n",
    "    # Evaluate the global model.\n",
    "    test_loss, test_acc = evaluate_model(glob_model, test_loader)\n",
    "    performance_log['g_test_loss'].append(test_loss)\n",
    "    performance_log['g_test_acc'].append(test_acc)\n",
    "    \n",
    "    participating_clients = sorted(np.random.choice(client_idxes, size=num_participation, replace=False))\n",
    "    print('participating_clients:', participating_clients)\n",
    "    \n",
    "    # Local training.\n",
    "    client_updates = dict()\n",
    "    for client_idx in participating_clients:\n",
    "        print('client:', client_idx)\n",
    "        client_loader = client_loaders[client_idx]\n",
    "        client_update = fl.local_update_fedcka(glob_model, prev_w_dict[client_idx], client_loader, num_local_epochs, optim, optim_args, fedcka_args)\n",
    "        for key in ['local_w', 'num_samples', 'train_loss', 'train_acc']:\n",
    "            client_updates.setdefault(key, list()).append(client_update[key])\n",
    "        prev_w_dict[client_idx] = copy.deepcopy(client_update['local_w'])\n",
    "        \n",
    "    # Model aggregation.\n",
    "    glob_w = fl.weighted_averaging(client_updates['local_w'], client_updates['num_samples'])\n",
    "    glob_model.load_state_dict(glob_w)\n",
    "    \n",
    "    # Average local performance.\n",
    "    performance_log['g_train_loss'].append(sum(client_updates['train_loss'])/len(client_updates['train_loss']))\n",
    "    performance_log['g_train_acc'].append(sum(client_updates['train_acc'])/len(client_updates['train_acc']))\n",
    "    \n",
    "    # Save global model.\n",
    "    if (round_no + 1) % save_interval == 0:\n",
    "        torch.save(glob_model.state_dict(), os.path.join(save_dir, 'g_r_{}.pth'.format(round_no + 1)))\n",
    "        torch.save(prev_w_dict, os.path.join(save_dir, 'prev_w.pth'))\n",
    "        utils.save_pickle(log_path, performance_log)\n",
    "    \n",
    "    for key in sorted(metric_keys):\n",
    "        print(key, ': ',  performance_log[key][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T07:16:46.489120Z",
     "start_time": "2022-10-06T07:16:00.424475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the final global model on clients.\n",
    "c_loss_list, c_acc_list = [], []\n",
    "for client_idx in range(num_clients):\n",
    "    client_loader = client_loaders[client_idx]\n",
    "    train_loss, train_acc = fl.evaluate_model(glob_model, client_loader, tqdm_desc='client {}/{}'.format(client_idx, num_clients))\n",
    "    c_loss_list.append(train_loss)\n",
    "    c_acc_list.append(train_acc)\n",
    "\n",
    "performance_log['final_g_train_loss'] = sum(c_loss_list) / len(c_loss_list)\n",
    "performance_log['final_g_train_acc'] = sum(c_acc_list) / len(c_acc_list)\n",
    "    \n",
    "# Evaluate the global model.\n",
    "test_loss, test_acc = evaluate_model(glob_model, test_loader)\n",
    "performance_log['final_g_test_loss'] = test_loss\n",
    "performance_log['final_g_test_acc'] = test_acc\n",
    "\n",
    "utils.save_pickle(log_path, performance_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T07:16:47.367698Z",
     "start_time": "2022-10-06T07:16:46.490581Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot training history.\n",
    "performance_log = utils.load_pickle(log_path)\n",
    "\n",
    "loss_plot_config = utils.LOSS_PLOT_CONFIG.copy()\n",
    "loss_plot_config['figsize'] = (12, 6)\n",
    "loss_plot_config['save_dir'] = os.path.join(save_dir, 'loss.png')\n",
    "loss_plot_config['show_img'] = True\n",
    "loss_plot_config['xlabel'] = 'rounds'\n",
    "loss_plot_config['labels'] = ['g_train_loss', 'g_test_loss']\n",
    "data_list = [\n",
    "    performance_log['g_train_loss'] + [performance_log['final_g_train_loss']],\n",
    "    performance_log['g_test_loss'] + [performance_log['final_g_test_loss']]\n",
    "]\n",
    "utils.save_plot(data_list, loss_plot_config)\n",
    "\n",
    "acc_plot_config = utils.ACC_PLOT_CONFIG.copy()\n",
    "acc_plot_config['figsize'] = (12, 6)\n",
    "acc_plot_config['save_dir'] = os.path.join(save_dir, 'accuracy.png')\n",
    "acc_plot_config['show_img'] = True\n",
    "acc_plot_config['xlabel'] = 'rounds'\n",
    "acc_plot_config['labels'] = ['g_train_acc', 'g_test_acc']\n",
    "data_list = [\n",
    "    performance_log['g_train_acc'] + [performance_log['final_g_train_acc']],\n",
    "    performance_log['g_test_acc'] + [performance_log['final_g_test_acc']]\n",
    "]\n",
    "utils.save_plot(data_list, acc_plot_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T07:16:48.431912Z",
     "start_time": "2022-10-06T07:16:47.368993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reload saved global model.\n",
    "if dataset_name == 'cifar_10' or dataset_name == 'svhn' or dataset_name == 'fashion_mnist':\n",
    "    glob_model = model.cnn(num_classes=num_classes)\n",
    "elif dataset_name == 'cifar_100' or dataset_name == 'tiny_imagenet_200':\n",
    "    glob_model = model.resnet20(num_classes=num_classes, image_size=img_size)\n",
    "    \n",
    "glob_model.to(device)\n",
    "glob_model.load_state_dict(torch.load(os.path.join(save_dir, 'g_r_{}.pth'.format(num_rounds))))\n",
    "\n",
    "# Evaluate the global model.\n",
    "test_loss, test_acc = evaluate_model(glob_model, test_loader)\n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T07:16:48.436955Z",
     "start_time": "2022-10-06T07:16:48.434145Z"
    }
   },
   "outputs": [],
   "source": [
    "# from cka import CKA, CudaCKA\n",
    "# import numpy as np\n",
    "\n",
    "# np_cka = CKA()\n",
    "\n",
    "# X = np.random.randn(1000, 100)\n",
    "# Y = np.random.randn(1000, 100)\n",
    "\n",
    "# print('Linear CKA, between X and Y: {}'.format(np_cka.linear_CKA(X, Y)))\n",
    "# print('Linear CKA, between X and X: {}'.format(np_cka.linear_CKA(X, X)))\n",
    "\n",
    "# print('RBF Kernel CKA, between X and Y: {}'.format(np_cka.kernel_CKA(X, Y)))\n",
    "# print('RBF Kernel CKA, between X and X: {}'.format(np_cka.kernel_CKA(X, X)))\n",
    "\n",
    "# cuda_cka = CudaCKA(device)\n",
    "\n",
    "# # X = torch.randn(10000, 100, device=device)\n",
    "# # Y = torch.randn(10000, 100, device=device)\n",
    "\n",
    "# X = torch.tensor(X, device=device, dtype=torch.float32)\n",
    "# Y = torch.tensor(Y, device=device, dtype=torch.float32)\n",
    "\n",
    "# print('Linear CKA, between X and Y: {}'.format(cuda_cka.linear_CKA(X, Y)))\n",
    "# print('Linear CKA, between X and X: {}'.format(cuda_cka.linear_CKA(X, X)))\n",
    "\n",
    "# print('RBF Kernel CKA, between X and Y: {}'.format(cuda_cka.kernel_CKA(X, Y)))\n",
    "# print('RBF Kernel CKA, between X and X: {}'.format(cuda_cka.kernel_CKA(X, X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T07:16:48.445447Z",
     "start_time": "2022-10-06T07:16:48.438152Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# cosine_similarity = torch.nn.CosineSimilarity(dim=-1)\n",
    "# torch.mean(cosine_similarity(X, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-10-06T01:18:27.832Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
